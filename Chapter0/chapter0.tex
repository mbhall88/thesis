%!TEX root = ../thesis.tex
%*******************************************************************************
%****************************** Introduction Chapter ***************************
%*******************************************************************************
\chapter{Background}

This thesis will focus on graph genome methods and their application to bacterial genomes. We pay particular attention to \mtb{} and \ont{} for our applications. i.e., why are we focusing on these particular topics in the background section?

% =============================================
\section{Bacterial genomes}
% Describe the concept of a bacterial pan-genome
% Describe some of the unique organisational elements of bacterial genomes - i.e., HGT, MGEs, recombination etc.
% How are pan-genomes analysed
% Variant calling in bacterial genomes
% Use the variant calling section to segway into graph genomes?
\subsection{Causes of bacterial diversity}
Bacteria have incredibly flexible genomes. The mechanisms of variation can be grouped into \emph{vertical} or \emph{horizontal} inheritance. Vertical inheritance is the passing of genetic material from parent to child during replication, while horizontal inheritance describes the acquisition of genetic information between cells without such an ancestor relationship. 

Vertically inherited variation generally consists of point mutations, insertions and deletions (indels), and structural rearrangements. Such mutations can arise due to a multitude of reasons: homologous recombination, DNA deamination, replication-transcript conflict, and replication errors to name a few \cite{Lan2000}. However, the dominant form of genomic variability in bacteria is horizontal inheritance \cite{McInerney2017}.

Horizontal inheritance operates via three main mechanisms - \textit{transduction}, \textit{conjugation}, and \textit{transformation} (or competence) - and are illustrated in \autoref{fig:horizontal-inheritance}.

\textit{Transduction} is mediated by bacteriophages (phages) - viruses which infect bacteria and are the most abundant organism on Earth \cite{mcgrath2007bacteriophage}. During phage propagation, parts of the host (bacteria) DNA can become encapsulated in the virus. If a phage goes on the infect another cell and eject this encapsulated DNA (transduction), it can recombine into the chromosome or begin replicating as a plasmid \cite{Chiang2019}. When the transduced DNA is a gene imparts a new, beneficial function, it can have obvious impacts on the recipient's evolution.

\textit{Conjugation} is the cell-to-cell transfer of DNA. A donor cell contacts another via a pilus and a copy of the DNA - normally a plasmid - is transmitted \cite{Soucy2015}. A more rare form of conjugation can occur when a plasmid has become incorporated into the chromosome of the donor (Hfr) and this portion of the chromosome is transferred to the recipient cell \cite{Redfield2001}.

\textit{Transformation} occurs when a cell interalises exogenous DNA, which in turn becomes incorporated into the chromosome by homologous recombination \cite{Johnston2014}. There is some debate about the exact purpose of transformation, with the general consensus being to increase genetic diversity; however, a nutritional role is also possible \cite{Johnston2014}.

\begin{figure}
\begin{center}
\includegraphics[width=0.95\columnwidth]{Chapter0/Figs/methods-of-dna-transfer.png}
\caption{{An illustration of the three main mechanisms of horizontal inheritance in bacteria. \textbf{a}) Transduction is facilitated by phages that encapsulate host DNA in one cell and eject that DNA into another cell. \textbf{b}) Conjugation, in its common form, is the transfer of a plasmid copy from a donor to a receiver cell via a pilus "bridge". In a rarer form, a plasmid that has been incorporated into the donor cell chromosome is transferred. \textbf{c}) Transformation (competence) is the uptake of exogenous DNA and subsequent incorporation into the chromosome.}
{\label{fig:horizontal-inheritance}}
}
\source{\cite{Redfield2001}}
\end{center}
\end{figure}

\noindent
These different means of inheritence conspire to create varying levels of diversity within bacterial species and give rise to the \textit{pan-genome}.

\subsection{The pan-genome}

A pan-genome is the full complement of genetic loci found within a given species. Traditionally, loci refer to genes, although we note that for the work we will describe in this thesis loci need not be genes.

The pan-genome can be broken into two subsets: the \textit{core} and \textit{accessory} genome. Loci that occur in the majority of species members are considered core, whilst everything else is deemed accessory (see \autoref{fig:pangenome-venn}). The accessory genome can be further broken down into intermediate and rare loci. 

The proportional size of the core genome varies dramatically between species. For instance, if we assume a gene is core if present in $\ge 95$\% of sampled species, the \textit{Escherichia coli} pan-genome is composed of 10\% core genes. Conversely, 89\% of the \textit{Mycobacterium tuberculosis} pan-genome is core genes (data was obtained from the panX database \cite{panx}). Species with a large pan-genome, such as \ecoli{}, have what is called an "open" pan-genome, while those with more conserved gene content, such as \mtb{}, are deemed "closed". 

Another interesting property of the bacterial genome is the distinctive "U-shaped" gene frequency distribution \cite{Lobkovsky2013,pandora,Lapierre2009}, shown in \autoref{fig:pangenome-freq}. This frequency distribution is a consequence of the fact that, in general, genes are either rare or common due to selective pressures \cite{Lobkovsky2013,thepangenome2020}. Moreover, the size of the bacterial pan-genome is estimated to be infinite \cite{Lapierre2009}, as hinted at by \autoref{fig:pangenome-size}.

\begin{figure}
     \centering
     \begin{subfigure}[b]{0.475\textwidth}
        \includegraphics[height=0.21\textheight]{Chapter0/Figs/pangenome-venn.png}
        \centering
        \caption{}
        \label{fig:pangenome-venn}
        \source{\cite{McInerney2017}}
     \end{subfigure}
     \begin{subfigure}[b]{0.475\textwidth}
         \centering
        \includegraphics[height=0.21\textheight]{Chapter0/Figs/gene_frequency_distribution.png}
         \caption{}
         \label{fig:pangenome-freq}
         \source{\cite{pandora}}
     \end{subfigure}
     \begin{subfigure}[b]{0.8\textwidth}
        \includegraphics[width=1\linewidth]{Chapter0/Figs/pangenome-size.png}
        \centering
        \caption{}
        \label{fig:pangenome-size}
        \source{\cite{Land2015}}
     \end{subfigure}
    \caption{The size and gene frequency distribution of the bacterial pan-genome. \textbf{a}) Venn diagram representation of the pan-genome and its core and accessory components. \textbf{b}) The asymmetric U-shaped gene frequency distribution for 10 genomes within 6 bacterial species. Genes are generally rare (left) or common (right). \textbf{c}) the size (y-axis) of the core (red) and accessory (blue; Pan) genome of \ecoli{} as more genomes are sampled (x-axis).}
        \label{fig:pangenome}
\end{figure}

\noindent
These definitions of the pan-genome components (core and accessory) are somewhat simplistic. Recent work by Horesh \etal{} has highlighted that these traditional definitions are biased by lineage sampling \cite{Horesh2021}. As an example, we have a collection of 100 genomes, with 50 being from the same lineage ($L_1$). Let us say gene \textit{abc} occurs in all 50 members of $L_1$, but none of the other 50 genomes. Under the traditional pan-genomic definitions, we would call \textit{abc} an intermediate gene. However, if we gathered a further 1,000 genomes, none of which are lineage $L_1$, \textit{abc} would now be considered rare. In the new pan-genome model proposed by Horesh \etal{}, loci are given a classification that is structure-aware. The \textit{abc} gene from the example would be classified as lineage-specific core. Other categories include multi-lineage and collection core, along with the same categories for intermediate, rare, and a new varied frequency class. The collection core is analogous to the traditional core, with everything else being the accessory genome - albeit with a much finer level of detail.

\subsection{How are pan-genomes analysed?}
\label{sec:analyse-pangenome}

Most pan-genomic analyses of bacterial collections follow a similar approach: align the genomes with a tool such as Parsnp \cite{Treangen2014} or Rory \cite{Page2015}, extract the core genome alignments and either ignore the accessory genome or just produce a presence-absence matrix of it \cite{Arnold2018,Azarian2018,McNally2016,thepangenome2020}. When the accessory genome is investigated at the nucleotide level, it is generally focused on a small subset of genes related to specific phenotypes such as antimicrobial resistance (AMR; \cite{Boolchandani2019}) or virulence \cite{Vasquez2019}. As we have seen, the pan-genome size varies significantly, so depending on the species, such approaches could be "ignoring" large portions of the full genomic repertoire. Despite this, we have learned an enormous amount about bacteria and their pan-genomes with these methods.

\subsection{Variant calling of bacterial genomes}
\label{sec:intro-bacteria-var-call}

A common (pan-)genomic analysis requirement, and a major focus of this thesis, is variant calling. However, depending on the application, this can be done in a number of different ways. For example, when characterising an outbreak, common approaches are to use a reference genome of the same, or very close, strain to the outbreak \cite{Taylor2015}, or assemble each sample and select the closest reference to it based on some typing strategy \cite{Wyres2021}. Alternatively, a reference-free approach can alleviate some of the reference bias induced when selecting a genome to call variants against and provide better resolution of an outbreak \cite{Cremers2020}.

Given the importance of bacterial variant calling to this thesis, we will briefly outline various approaches to calling variants in bacterial genomes and highlight their strengths and limitations.

\subsubsection{Alignment-based methods}

Alignment-based variant calling also assumes a reference genome is provided. In this mode of variant calling, raw sequencing reads are aligned to a given reference genome to generate a Sequence Alignment/Map (SAM) file. Common software programs used to perform these alignments for bacterial variant calling include BWA-MEM \cite{li2013}, Bowtie2 \cite{bowtie2012}, and Novoalign (\url{http://www.novocraft.com/products/novoalign}) for short (Illumina) read technology. (\ont{}-based variant calling will be detailed in \autoref{sec:ont-var-calling-intro}, for now we focus on Illumina-based sequencing reads). 

Where variant calling programs distinguish themselves is in how they handle the alignment information. This includes, but is not limited to, the number of base calls disagreeing with the reference, the quality of the read alignment, the alignment location of a read pair, or the quality score of the mapping \cite{Olson2015}. Popular methods for calling variants generally employ either Bayesian, likelihood, or machine learning algorithms to infer candidate variants given this alignment data. While many of these models were designed with human variant calling in mind, a selection have shown themselves to be perfectly applicable to bacteria. The most frequently used Bayesian method for bacterial variant calling is Freebayes \cite{Garrison2012}, however, it is generally used via a wrapper, Snippy (\url{https://github.com/tseemann/snippy}), which handles the alignment (BWA-MEM), variant calling (Freebayes), and additionally applies filters to the resulting VCF file. Of the likelihood-based callers, Samtools/BCFtools \cite{bcftools2021,samtools2009} and GATK \cite{Poplin2018} tend to be most often employed. 

\subsubsection{Alignment-free methods}
% kSNP - uses k-mers to find SNPs, cannot detect k-mers within k positions, cant do indels, requires extensive pre-QC filtering as it cant deal with sequencing errors - https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0081760
Methods that do not align reads to a reference genome typically use \kmer{}-based methods for variant inference. FastGT \cite{fastgt2017} and LAVA \cite{lava2016} are two such programs that require a database of known variants and use \kmer{} counts in a sample to determine the presence of any of these variants. The major limitation with these tools though is their inability to call variants not present in the database provided. Kestrel \cite{kestrel2017} is a \kmer{}-based variant caller that can discover \denovo{} variants and does this by detecting unique \kmer{}s in a sample with respect to a given reference genome. However, Kestrel is not strictly alignment-free, as it does use local alignment to place candidate variants in relation to the reference genome. Additionally, it was shown to have a much lower sensitivity than an alignment-based method. 

Another popular alignment-free single nucleotide polymorphism (SNP) caller is kSNP, which finds SNPs \emph{between} samples by detecting \kmer{}s where the central base varies \cite{ksnp2015}. It is regularly used in outbreak settings where differences between samples are crucial \cite{Bazan2017,Raphael2016,Chochua2017}. However, kSNP cannot detect SNPs within $k$ positions (bases) of each other, is unable to detect indels, and cannot deal with sequencing errors - requiring extensive pre-filtering.

A benchmark of many alignment-free methods for various sequence analysis applications can be found in \cite{Zielezinski2019}. 

\subsubsection{Assembly-based methods}

There are two forms of assembly-based variant calling. In the first, an assembled genome for a sample (or samples) is compared to a reference via whole genome alignment. Software such as MUMmer \cite{mummer2018} or Minimap2/paftools \cite{li2018} facilitate this assembly-to-assembly alignment and then identify positions where the two disagree. An assembly-based method that is prevalent in bacterial genomics is Parsnp \cite{Treangen2014}, which aligns the \emph{core} genome of assemblies and then calls SNPs (only) \emph{between} those genomes. A major limitation with these types of assembly-based approaches is there is no sense of the quality of calls. As an assembly naturally has a read depth of 1x at all positions, there is no information about variant support - all variants are considered equal in this scheme.

The second form of assembly-based variant callings bundled assembly and genotyping. Cortex \cite{iqbal2012} \denovo{} assembles a sample from sequencing reads and genotypes variants at "bubble" sites in its de Bruijn graph. It produces variant calls with respect to a provided reference genome and has been used extensively in bacterial genomics \cite{bradley2015,hunt2019,Stasiewicz2015,Young2017,Lees2017}.

\hspace{0.75cm}

\noindent
A comprehensive benchmark of alignment-based variant calling found that the choice of reference genome, rather than the choice of tools, has the most critical impact on accuracy \cite{Bush2020}. The best general-purpose pipeline was found to be Snippy, however, they note that species-specific filtering of the final VCF file can cause the performance of many tools to converge.

Reference genome bias is perhaps the single biggest limitation of most aforementioned variant calling approaches \cite{Bertels2014,Bush2020,Olson2015}. The bacterial pan-genome highlights this impediment in a stark way. As an illustration of this, \autoref{fig:reference-bias} shows a cartoon depiction of the "single-reference problem". In this figure, we see that no two genomes contain the same full set of loci - exactly what we expect from nearly any pan-genome \cite{McInerney2017}. As such, the use of any of these genomes as a reference to call variant against will inevitably mean we are unable to describe variants in loci not found in both the reference and query genomes. This type of bias is termed \emph{hard} reference bias. Another, more subtle, form is \emph{soft} reference bias, which results difficulties aligning to the reference due to divergence in shared loci between the reference and query, especially around structural variants \cite{Price2017,Olson2015,Pightling2014}. However, these biases tend to impact clonal species, such as \mtb{}, much less than those with open pan-genomes \cite{Bush2020}.

\begin{figure}
\centering
\includegraphics[height=0.35\textheight]{Chapter0/Figs/single_ref_problem.png}
\caption{An illustration of the single-reference problem. Each vertical column depicts a genome, with the coloured blocks representing loci (genes). The numbers next to each locus indicate a variant with respect to other loci of the same colour. The percentage figures at the bottom of each genome indicate what percentage of variants in the other genomes could be found by a perfect variant caller if that genome was used as a reference. Note, not all genomes contain the same loci, hence no genome can capture all of the variants.}
\label{fig:reference-bias}
\source{\cite{rachelthesis,pandora}}
\end{figure}

Given these biases resulting from the use of a single reference genome, an alternative solution is needed. One solution that is rapidly maturing is the use of a \emph{genome graph} to replace a single reference.

% =============================================
\section{Genome graphs}

Genome graphs are a way of representing variation within a population; be it a bacterial species, a human gene, or a viral quasi-species \cite{comp-pan-genomics}. \autoref{fig:graph-representation} illustrates a generic representation of a genome graph, where redundant information (consensus) is collapsed into a linear sequence and variation is represented as divergent paths leading in and out of these linear segments. A walk through such a graph represents a mosaic of the population variation used to construct the graph. 

A rich array of algorithms and methods have been proposed for representing and operating on genome graphs across all kingdoms of life \cite{Sherman2020,Eizenga2020,comp-pan-genomics}. In this section, we will highlight some mature genome graph frameworks, along with their limitations. In the context of this thesis, these limitations will focus on the applicability of a method to the bacterial pan-genome. We follow these existing methods by introducing a new genome graph approach relevant to this thesis.

\begin{figure}
\centering
\includegraphics[width=0.75\columnwidth]{Chapter0/Figs/graph-representation.png}
\caption{Conceptual representation of a genome graph. \textbf{a}) Variants lead to a "bubble", or divergent path. Note, the second bubble represents an insertion/deletion. \textbf{b}) Variation can be arbitrarily nested. In this example, there are is a SNP within an insertion.}
\label{fig:graph-representation}
\source{\cite{Sherman2020}}
\end{figure}

\subsection{Existing methods}
\label{sec:graphs-existing}

\subsubsection{GraphTyper}
GraphTyper \cite{graphtyper,graphtyper2} represents a genome graph as a directed acyclic graph (DAG) based on a reference sequence plus known variants (similar to \autoref{fig:graph-representation}, but with directional). Sequencing reads are mapped to the reference genome with BWA-MEM. The reference sequence is then broken into 50kbp regions and reads are realigned to the graph in the respective region they map to. A path through the graph for the read is detected using a seed-and-extend approach and variants are genotyped based on the read support from this alignment. Impressively, GraphTyper can genotype SNPs, indels, and complex and structural variants.

In the context of bacterial genomes, there are a number of limitations with GraphTyper. First, a single reference genome is used as the backbone of the graph; a feasible solution for humans, but not for bacteria, where, as we have seen, two genomes likely do not have an identical gene repertoire. Second, the initial alignment of reads to the single reference genome suffers the same soft and hard reference bias discussed in \autoref{sec:intro-bacteria-var-call}. The realignment of reads reduces the soft reference bias compared to linear genome methods, however the hard bias remains. Third, no long-read sequencing technology support is available, and is unlikely to be possible with the current seed-and-extend approach used for alignment \cite{li2018}. 

\subsubsection{Variation graph toolkit}
The Variation Graph Toolkit (VG) \cite{vg2018} is a suite of tools for constructing, mapping, and calling variant from genome graphs. The representation used by VG is an \emph{un}directed, potentially cyclic, graph. Variation graphs can be constructed from a single reference and associated VCF file, or from multiple genome assemblies. Read alignment to the graph uses a seed-and-extend approach. Variant calls are made via a basic read pileup on the graph and then augmenting the original graph with novel candidates, followed by genotyping \cite{Novak2017}.

As with GraphTyper, the use of seed-and-extend alignment makes the support of long reads unlikely. (We note there has discussions within the VG GitHub repository for 4 years about supporting long reads, however, as yet, no support has been announced). Another limitation of VG is that in order to produce variant calls, the user must provide a reference genome, again, either inheriting reference bias or requiring a verbose description of simple variants (see \autoref{sec:pandora-compare} for an elaboration of this point).

A major limitation of VG is its computational resource requirements. As VG attempts to be a "general" method - i.e., it is undirected and allows cycles so as to naturally allow events such as inversions and repeats - it is CPU and disk intensive \cite{strainflair2021,gramtools2021,minigraph2020} to the point of requiring over 1 terabyte of temporary disk space to construct a graph \cite{gramtools2021}, or not being useable \cite{minigraph2020}.

\subsubsection{Minigraph}
Minigraph \cite{minigraph2020} represents a genome graph as a bidirectional graph, which allows cycles. The construction process starts with a single genome and iteratively adds structural variants (SVs; regions of divergence $\ge 100$bp and $\le 100$kbp). In each round, a genome is aligned to the existing graph (a linear sequence in the beginning) and the graph is augmented with sequence from poorly mapped regions (SVs). Minigraph aligns sequencing reads or assemblies to this graph using a modified version of minimap2's minimizer \kmer{}-based seed-and-chain approach \cite{li2018}. As such, Minigraph should be easily adaptable to longs.

As Minigraph only incorporates SVs of 100bp or longer, it does not variant-call in the typical sense. It instead produces a BED-like file that calls SVs from the alignment. This is the main limitation of Minigraph: it cannot call variants smaller than 100bp, which are especially important in bacterial genomes. The authors ackowledge this limitation and state that the reason for this exclusion is that smaller variants can be easily identified with standard approaches. 

\subsubsection{Gramtools}
Gramtools \cite{gramtools2016,gramtools2021} depicts a genome graph as a DAG that can be constructed from either a single reference and associated VCF file, or from a multiple sequence alignment (MSA) - in fact it uses the same model outlined below in \autoref{sec:make_prg}. Alignment of sequencing reads is facilitated by the variation-aware Burrows-Wheeler Transform (vBWT) \cite{gramtools2016}, which is an extension of the original linear BWT to graphs. It genotypes variants under a haploid or diploid likelihood-based model and produces the variant calls in the standard VCF or a new JSON-like VCF (jVCF) file, which stores the standard VCF information, with the addition of graph-relevant details the nesting of sites \cite{gramtools2021}. As with the other genome graph methods though, Gramtools only support short Illumina sequencing data, and is unlikely to be able to support long reads with a higher error rate than Illumina.

\noindent
All of the existing methods require an enforced ordering - i.e., loci are not considered independently. Despite the fluidity of bacterial genomes, there is surprisingly conserved gene ordering \cite{Tamames2001,Rocha2008}, however, the enforced order of these genome graphs cannot account for variations in gene repertoire - i.e., the pan-genome. VG has been applied to bacteria for strain-typing and abundance estimates in \ecoli{}, however, individual graphs had to be concatenated together for each gene, enforcing an order \cite{strainflair2021}. None of the methods to our knowledge natively allows independence of loci and require custom pipeline such as \cite{strainflair2021} to approximate this behaviour. Additionally, no existing genome graph method supports long read sequencing reads such as \ont{}.

These limitations are the driving motivation for the development of the genome graph method Pandora.

\section{Pandora: bacterial pan-genomics with reference graphs}
\label{sec:pandora-intro}

As we have seen, the bacterial pan-genome can be amazingly diverse at both the nucleotide and gene (locus) level. The use of a single reference to describe such variation is inadequate and the pan-genome seems a perfect application for genome graphs. However, existing methods fail to allow for structural differences at the locus level (\autoref{sec:graphs-existing}) and therefore are unable to describe nucleotide-level variation in the accessory genome. Another common limitation of existing genome graph tools is the lack of support for long-read sequencing technologies (we outline the significance of this in \autoref{sec:intro-ont}).

Pandora is a genome graph method that addresses these limitations. Rachel Colquhoun developed \pandora{} during her PhD thesis \cite{rachelthesis}; we provide a brief overview of its methodology here as we extend and apply it throughout this thesis.

\subsection{Population reference graph construction}
\label{sec:make_prg}

The genome graph representation used by \pandora{} is a DAG. However, unlike Gramtools, which uses the same representation \cite{gramtools2021}, \pandora{} is agnostic to locus ordering. Instead, \pandora{} interprets a genome graph (interchangeably referred to as a \emph{reference graph}) at two levels: locus and pan-genome. We call a locus-level reference graph a \emph{population reference graph} (\prg{}) as it represents the variation within a given population for a locus. A \prg{} is not restricted in its scope for a locus; it can be a gene, and intergenic region, and operon, or any other grouping desired. A pan-genome-level reference graph is termed a \emph{pan-genome reference graph} (\panrg{}) and is a collection of \prg{}s. Again, a \panrg{} is not limited in its scope; it could describe a pan-genome, a meta-genome, or a collection of antimicrobial resistance-associated genes.

Construction of a \prg{} is accomplished with a recursive cluster and collapse algorithm, implemented in the software program \makeprg{} (\url{https://github.com/iqbal-lab-org/make_prg}). Two parameters are key to this process: the minimum match length, $m$, and the maximum nesting level, $n$. Starting with an MSA of locus sequences, when $\ge m$ positions agree, they are collapsed into a single sequence. Each section of the MSA which is not collapsed is recursively clustered, with (sub)sequences in the cluster being collapsed if possible, or clustered again. This recursive clustering and collapsing continues until all clusters contain a single sequence or recursion has occurred more than $n$ times. This process is illustrated in \autoref{fig:make-prg-rcc}, which uses $m=4$ and $n\ge 2$.

\begin{figure}
\centering
\includegraphics[width=1\columnwidth]{Chapter0/Figs/make-prg.png}
\caption{Construction of a locus reference graph (\prg{}) from a multiple sequence alignment (MSA; left) with the recursive cluster and collapse algorithm implemented in \makeprg{}. Vertical slices in the MSA are collapsed when there is a minimum match length of 4. Sections not collapsed are recursively clustered, and if possible, collapsed, until no further clustering is possible, or a maximum nesting level is reached. In this example, a nesting level of 2 is reached.}
\label{fig:make-prg-rcc}
\source{\cite{rachelthesis,pandora}}
\end{figure}

\subsection{Index, quasi-map, and sequence inference}

\subsubsection{$(w,k)$-minimizers}
A core concept within \pandora{} is $(w,k)$-minimizers \cite{Roberts2004} - interchangeably referred to as minimizer (or minimizing) \kmer{}s. A $(w,k)$-minimizer is a representative \kmer{} from a collection of $w$ consecutive \kmer{}s in a string (sequence). The function used to select this representative can use any ordering one prefers; \pandora{} uses the same ordering strategy as minimap \cite{minimap2016} - the \kmer{} with the minimum invertible integer hash function value. The purpose of minimizer \kmer{}s is to reduce the number of \kmer{}s required to represent a sequence, but ensuring that if two string share a significant exact match, they will share at least one minimizer. Additionally, \pandora{} requires $w\le k$, so that all bases in the \prg{} are guaranteed to be covered by a minimizer, except, at most, the $w-1$ bases at the ends of the sequence.
% pandora concepts I need to cover 

\subsubsection{Indexing}
Each \prg{} is represented within \pandora{} as a minimizer \kmer{} graph. This graph is constructed by walking all paths in the \prg{} and selecting minimizer \kmer{}s as outlined above. As $w\le k$ is enforced, walking each path ensures every site within the graph is covered by a minimizer. The index of a \panrg{} is a map from a minimizer \kmer{} to the position(s) and \prg{}(s) it occurs in. 

\subsubsection{Quasi-mapping}
Quasi-mapping - as opposed to mapping - is a form of approximate alignment. The goal of quasi-mapping is to identify which locus (or loci) a read originates from, and \emph{roughly} where within that locus each section of the read maps. To perform this quasi-mapping, \pandora{} looks up all $(w,k)$-minimizers of a read in the index. For every minimizer in the read that occurs in the index, a \emph{hit} is defined as the read and \prg{} positions of that minimizer. A single read minimizer can have multiple hits if the minimizing \kmer{} occurs in multiple locations in the \panrg{}. As such, once all hits are identified, they are filtered to remove spurious ones. This filtering is done by keeping only those hits that cluster together on a read, and only occur in a single \prg{}. All \prg{}s that are associated with a cluster of hits is deemed present in the sample, while the remaining loci are considered absent.

\subsubsection{Sequence inference}
A major reason for \pandora{}'s reduced reference bias is that rather than requiring the user to provide a reference genome, it asks for a \panrg{} and infers the closest sequence in that \panrg{} to the sample under consideration. As we saw in \autoref{sec:intro-bacteria-var-call}, choice of reference is often the biggest limitation when calling variants in bacterial genomes.

For each \prg{} deemed present after quasi-mapping, \pandora{} has (filtered) coverage information for the minimizers in the \kmer{} graph. A dynamic programming algorithm is used to find the path through the \kmer{} graph which maximises the log-likelihood score. This inferred sequence (path) is also referred to as the \emph{maximum likelihood path}.

\subsection{Variation inference}

\subsubsection{Single-sample}
The single-sample variation inference mode of \pandora{}, which is coordinated by the \map{} routine, quasi-maps sequencing reads and infers a sequence for each \prg{} within the given \panrg{}. In addition, if requested, \map{} will also genotype the sample against the maximum likelihood path for each \prg{} (or a user-provided sequence if it exists). Genotyping occurs for all variation sites within the \prg{} and is returned as a VCF file. An example of this single-sample genotyping and VCF is depicted in \autoref{fig:map-var-representation}.

\subsubsection{Multi-sample}
\label{sec:pandora-compare}
Variation inference can also be performed for a collection of samples with the \compare{} protocol. This type of analysis has traditionally been plagued by reference bias problems. If the collection of samples are of the same strain, then analysis against the same reference is not problematic, but once even a single sample originates from a different strain, the pan-genome exerts itself. As we outlined in \autoref{sec:analyse-pangenome}, analysing divergent samples generally works by looking at variation in the core, while resorting to locus presence-absence in the accessory genome. Multi-sample inference with \compare{} offers the best of both worlds; variation is inferred for both the core and accessory genome. Where a locus is absent from a sample, all sites for that locus are represented with a null genotype. In this approach, if a locus is present in only 2/20 samples in the collection, variants are inferred for the two samples.

To allow this multi-sample variation inference, \pandora{} infers the maximum likelihood path for each sample. Then, using the same dynamic programming algorithm, \pandora{} infers a maximum likelihood path for \emph{the collection} of samples; instead of \kmer{} coverage, the number of maximum likelihood paths covering each minimizer is used for inferring the most likely path. In the end, the inferred sequence is selected to be maximally close to all samples in the collection. The consequence of this is that all samples are genotyped against the same reference at all variant sites, making direct sample comparisons possible. This approach also ensures that small difference between samples are described as such - as shown in \autoref{fig:var-representation}.

\begin{figure}
     \centering
     \begin{subfigure}[b]{0.95\textwidth}
        \includegraphics[width=0.95\columnwidth]{Chapter0/Figs/map_variation_representation.png}
        \centering
        \caption{Single-sample variation inference}
        \label{fig:map-var-representation}
        \source{\cite{rachelthesis}}
     \end{subfigure}
     \begin{subfigure}[b]{0.95\textwidth}
         \centering
        \includegraphics[width=0.95\columnwidth]{Chapter0/Figs/variant_representation.png}
         \caption{Multi-sample variation inference}
         \label{fig:var-representation}
         \source{\cite{rachelthesis,pandora}}
     \end{subfigure}
     \caption{The impact of sequence inference choice on variant representation. In both \textbf{(a)} and \textbf{(b)} the left panel (a) shows the \prg{}. \textbf{a)} the blue line indicates the inferred sequence (maximum likelihood path). b and c show how the choice of this sequence effects the representation of variant sites when genotyping. \textbf{b}) the black line indicates the multi-sample inferred sequence, while the blue and orange lines are two different samples. b and c show that by inferring the sequence that is maximally close to the two samples (c), small differences between the samples are represented as small variants.}
     \label{fig:pandora-var-representation}
\end{figure}

\hspace{0.75cm}

\noindent
The \pandora{} method addresses the main limitations of existing genome graph approaches (\autoref{sec:graphs-existing}) in the context of bacterial pan-genomes. In particular, \pandora{} supports both short (Illumina) and long (\ont{}) sequencing reads and removes hard reference bias by letting go of locus ordering and genotyping loci regardless of their genomic context.

Despite these advantages, there is a key limitation to the method: an inability to detect novel variants. As variation inference is done by genotyping all sites in a \prg{}, it follows that if a variant does not exist in a \prg{}, it cannot be detected by \pandora{}. The first chapter of this thesis (\autoref{chap:denovo}) will remove this limitation. 

% =============================================
\section{\ont{} DNA sequencing}
\label{sec:intro-ont}
A description of how this sequencing technology works.

Basecalling and historical progress in accuracy. %Make sure to mention some elements like NNs that are relevant to tubby

Discuss benefits over Illumina - i.e., portability, low startup requirements, real-time results etc.

\subsection{Variant calling}
\label{sec:ont-var-calling-intro}
Variant calling - discuss history of nanopolish and recent works on variant calling such as Clair and others

% =============================================
\section{Tuberculosis and its causative agent}

Overview of the diseases and bug.

What diagnostics are available, when and how are they used

Clinically relevant applications for WGS to TB

Transmission clustering - history of this work up to "Beyond the SNP threshold"

AMR - history of this work up to mykrobe and cryptic

\subsection{Using genome graph for drug resistance prediction}
\label{sec:genome-graphs-dst}

% \drprg{} is not the first tool to use the concept of genome graphs for AMR prediction. mykrobe, the other tool used in this chapter, uses population genome graphs for genotyping of samples. The underlying method mykrobe uses is Cortex \cite{iqbal2012} - a program that uses coloured de Bruijn graphs (dBGs) for genotyping samples via \denovo{} assembly. Cortex is somewhat of a precursor to \pandora{} - the genome graph method underpinning \drprg{}. However, \pandora{} offers a number of advantages over Cortex (see \autoref{sec:genome-graphs-dst} for a full description of these). The first being the representation of the genome graph itself. As mentioned, Cortex uses \kmer{}s in coloured dBGs, while \pandora{} uses minimizing \kmer{}s in a \emph{directed} graph. In the context of \ont{} data, this distinction is important. As we saw in \autoref{chap:denovo}, build dBGs from \ont{} creates very complex graphs. In addition, as the \ont{} error rate is higher than Illumina, a smaller \kmer{} size is required, another factor that increases the complexity of the dBG. Another important difference in the graph representations of Cortex (mykrobe) and \pandora{} (\drprg{}) is the way in which \kmer{} "hits" are encorporated. In a dBG, anywhere that a \kmer{} matches, the depth is incremented by one. However, in \pandora{} such hits are dependent on the context of the read. If a \kmer{} matches two locations in the graph, but one location has many hits close by from the same read while the other does not, the spurious hit is discarded. This filtering of \kmer{} hits allows us to use a lower \kmer{} size ($k=15$) in \pandora{}, and thus \drprg{}, than is used by Cortex/mykrobe ($k=21$). Another flow-on effect of using a smaller \kmer{} size is we do not require as much read depth in \drprg{} as there is a much higher chance of matches to smaller \kmer{}s, especially when the error rate is high. For example, assuming a \ont{} error rate of 0.08, we would expect the probability of a $15-mer$ and $21-mer$ having no errors to be 0.30 and 0.19 respectively. A more in-depth discussion of the differences between these graph methods can be found in (LINK\todo{link to intro section discussing cortex/pandora differences}).

% =============================================
\section{Executive summary of this thesis}

Here I will given an overview of what things we address in each chapter