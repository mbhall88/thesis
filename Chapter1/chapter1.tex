%!TEX root = ../thesis.tex
%*******************************************************************************
%*********************************** First Chapter *****************************
%*******************************************************************************

\chapter{Variant discovery in genome graphs}
\label{chap:denovo}
\ifpdf
    \graphicspath{{Chapter1/Figs/Raster/}{Chapter1/Figs/PDF/}{Chapter1/Figs/}}
\else
    \graphicspath{{Chapter1/Figs/Vector/}{Chapter1/Figs/}}
\fi
% ==================================================================
\setcounter{section}{-1}
\section{Publication and collaboration acknowledgements}
\label{sec:denovo-acknowledge}
% ==================================================================
\section{Introduction}

% ==================================================================
\section{Methods}
\label{sec:denovo-method}

We define a method that extends \pandora{}, with a subcommand \vrb{discover}, to allow for the \denovo{} discovery of variants not present a \prg{}. It is implemented within the \pandora{} code base, in the C++ programming language. 

The first step of \denovo{} variant discovery in genome graphs is finding the candidate regions of the graph that show evidence of dissimilarity from the sample's reads.

\subsection{Finding candidate regions}

The input required for finding candidate regions are a local \prg{} (node), $n$, within the \pandora{} \panrg{}; the maximum likelihood path of both sequence and \kmer{}s in $n$, $lmp_n$ and $kmp_n$ respectively; and a padding size, $w$, for the number of positions surrounding the candidate region to retrieve.

We define a candidate region, $r$, as an interval within $n$ where read depth (coverage) on $lmp_n$ is less than a given threshold, $c$, for more than $l$ and less than $m$ consecutive positions. We note that coverage is actually stored on $kmp_n$, but is stored for the whole \kmer{}. We convert the coverage on $kmp_n$ into per-position coverage on $lmp_n$ and use that for identifying low-coverage segments as just described. $m$ acts to restrict the size of variants we are able to detect. If set too large, the following steps become much slower due to the combinatorial expansion of possible paths. 

For a given read, $s$, that has a mapping to $r$, we define $s_r$ to be the subsequence of $s$ that maps to $r$, including an extra $w$ positions either side of the mapping. We define the pileup $P_r$ as the set of all $s_r \in r$.

\subsection{Enumerating paths through candidate regions}
\label{sec:path-enum}

For $r \in R$, where $R$ is the set of all candidate regions, we construct a de Bruijn graph $G_r$ from $P_r$ using the GATB library \cite{gatb2014}. 

$A_L$ and $A_R$ are defined as sets of \kmer{}s to the left and right of $r$ in the maximum likelihood path $lmp_n$. They are anchors to allow insertion of new sequences found by \denovo{} discovery into the local \prg{}. Each set has a maximum size of $k$.

We abandon \denovo{} discovery if $A_L \cap G_r = \emptyset \lor A_R \cap G_r = \emptyset$. That is, if no pairwise combination of left and right anchor \kmer{}s exists in the de Bruijn graph $G_r$.

We use sets of \kmer{}s for $A_L$ and $A_R$, rather than a single anchor \kmer{}, to provide redundancy in the case where sequencing errors cause some anchors to not be in $G_r$. We define the start anchor \kmer{}, $a_L$, as the first (left-most) $a_L \in A_L \land a_L \in G_r$. Likewise, we define the end anchor \kmer{}, $a_R$, as the left-most $a_R \in A_R \land a_R \in G_r$.

Now that we have two anchor \kmer{}s, $a_L$ and $a_R$, our goal is to find all (valid) paths between these anchors in the de Bruijn graph ($G_r$).

$T_r$ is the spanning tree obtained by performing depth-first search (DFS) on $G_r$, beginning from $a_L$. $p_r$ is defined as a path, from the root node $a_L$ of $T_r$ and ending at node $a_R$, which fulfils the following two conditions:

\begin{enumerate}
  \item $p_r$ is shorter than the maximum allowed path length.
  \item No more than $k$ nodes along $p_r$ have coverage $< (0.1 n_r e_r)$, where $e_r$ is the expected \kmer{} coverage for $r$ and $n_r$ is the number of iterations of path enumeration for $r$.
\end{enumerate}

$V_r$ is the set of all $p_r$. If $|V_r|$ is greater than a predefined threshold, $n_r$ is incremented by 1 and $V_r$ is repopulated. If $0.1n_r = 1.0$ then \denovo{} discovery is abandoned for $r$.

The second condition listed above, which relies on $n_r$ and $e_r$ has the effect of progressively increasing the amount of coverage we demand on a candidate path ($p_r$). In the first iteration, $n_r=1$, therefore we require the path has 10\% of the expected read depth (coverage). If this yields too many paths (condition 1), we restart and require all paths to have 20\% of the expected coverage. If we reach a stage where we require 100\% of the expected coverage, but still have too many paths, we quit \denovo{} discovery for the candidate region.

\subsubsection{Pruning the path-space in a candidate region}

As \pandora{} operates on both accurate and error-prone sequencing reads, the number of valid paths in $G_r$ can be very large. In testing, we found the path enumeration process can result in runtimes beyond seven days in some scenarios. The increased runtime is due to cycles that can occur in $G_r$ and exploring paths that will never reach our required end anchor ($a_R$). 

In order to reduce the path-space within $G_r$, we prune paths based on multiple criteria. Critically, this pruning happens at each step of the graph walk (path-building; \autoref{sec:path-enum}).

In addition to $T_r$, obtained by performing DFS on $G_r$, we produce a distance map $D_r$ that results from running reversed breadth-first search (BFS) on $G_r$, beginning from \emph{the end anchor} ($a_R$). We say reversed BFS as we explore the \emph{predecessors} of each node, rather than the successors. $D_r$ is implemented as a binary search tree where each node in the tree represents a \kmer{} in $G_r$ that is reachable from $a_R$ via reversed BFS. Each node additionally has an integer attached to it that describes the shortest path from that node to $a_R$.

We can use $D_r$ to prune the path-space as follows. As we walk (enumerate) the candidate path ($p_r$) in \autoref{sec:path-enum}, for each node (\kmer{}; $v$) in $G_r$, starting at $a_L$, we check if $a_R$ be reached from $v$ in a minimum of $i$ nodes, where $i$ is defined as the maximum allowed path length minus the number of nodes walked to reach $v$. If one of these conditions is not met, we abandon $p_r$. 

The advantage of this pruning process is that we never explore paths that will not reach our required end point. Additionally, we will discard any path once we have made too many loops around a graph cycle.

\noindent
In the end, for each candidate region ($r$), we are left with a collection of paths ($V_r$) between two \kmer{}s ($a_L$ and $a_R$). We create the final candidate paths by replacing the sequence between $a_L$ and $a_R$ in the maximum likelihood path ($lmp_n$) with each path ($p_r$) in $V_r$. These are written to file - with one file per candidate region. Padding the candidate paths in this way ensures they are inserted into the \prg{} in the correct location (see \autoref{sec:denovo-insert}). 

\subsection{Updating a \panrg{} with candidate paths}
\label{sec:denovo-insert}

As new paths alter the structure of a \prg{}, we cannot insert them directly, and must rebuild each \prg{} for which a candidate path is discovered.

The first step of rebuilding each local \prg{} is to add the new candidate paths to the original multiple sequence alignment (MSA). Because we padded each path with the maximum likelihood path, this ensures the novel path aligns with the correct section of the locus. We combine all candidate paths for a locus into a single, unaligned FASTA file and add them to the existing locus MSA with the \vrb{--add} routine in MAFFT \cite{katoh2012}. 

Next, \makeprg{} is run on the subsequent alignments, and the resulting updated local \prg{}s are combined into a single \panrg{} and indexed with \pandora{}. 

This updated \panrg{} can then be used as input to \pandora{} and subsequent genotyping will include the novel variants.

% ==================================================================
\section{Simulations}
Having described an extension of the \pandora{} program that allows for \denovo{} variant discovery, we now turn our attention to its evaluation.

The first step in evaluating the effect of adding \denovo{} variant calling to \pandora{} is with a simulated dataset. We aim to show that the addition of \denovo{} discovery allows \pandora{} to improve its probability of variant detection (recall) with minimal impact on the quality of the calls (precision). 

To construct our simulated dataset, we randomly select 100 gene MSAs from a pool of 29,702 obtained for \ecoli{} from the panX database \cite{panx}. Next, a local \prg{} is constructed for each MSA with \makeprg{}. We used a range of maximum nesting levels (\todo[inline]{link to intro section on make prg}) - 1, 3, 5, and 10 - in order to investigate whether \prg{} nesting has an impact on our ability to discover novel variants. The local \prg{}s are combined into a single \panrg{} for each nesting level. A random path through each \prg{} is selected using \pandora{} and concatenated together to form a single "genome" sequence. 

We subsequently add SNPs to the simulated genome at different rates of SNPs per-gene using \vrb{snp-mutator} \cite{snpmutator}. For this work, we introduce 100, 400, and 1,000 SNPs to the simulated genome, which equate to approximately 1, 4, and 10 SNPs per gene, respectively. \vrb{snp-mutator} produces a VCF of the SNPs that were introduced, along with the mutated genome sequence.

Next, we simulated 30,000 \ont{} reads from the mutated genomes using \vrb{nanosim-h} \cite{yang2017,brinda2018}. As the most recent model offered by \vrb{nanosim-h} was from the old R9 \ont{} flow cell, we trained and used a model from a freely-available \ecoli{} R9.4 dataset (\url{http://lab.loman.net/2017/03/09/ultrareads-for-nanopore/}). Each read set was randomly subsampled to a read depth (coverage) of 15, 30, 60, and 100 with \vrb{rasusa} \cite{rasusa2019} so we can investigate the impact of coverage on our ability to discover novel variants.

\pandora{}'s \vrb{discover} routine is then run, using the original panX-derived \panrg{} and the reads simulated from the mutated genome. With this approach, we know that the reads originate from a sequence in our \panrg{}, but with some SNP differences and \ont{} errors. It is possible that some of the random SNPs introduced by \vrb{snp-mutator} already exist in the \panrg{}, but this is likely to be a very small number. We use three different \kmer{} sizes for the \denovo{} discovery: 11, 13, and 15. 

After running the \vrb{discover} routine, we are left with a collection of candidate paths produced by the \denovo{} component. We then add these candidate paths back into the \panrg{} as per \autoref{sec:denovo-insert}. The updated \panrg{} is then used as input - along with the simulated reads - to \pandora{} \vrb{map} to produce a genotyped VCF that hopefully contains all of the simulated SNPs.

In parallel to this, we also run \pandora{} \vrb{map} on the original \panrg{} and simulated reads - i.e., without variant discovery. The genotyped VCF produced by this run shows how \pandora{} performed prior to the addition of \denovo{} variant discovery in this chapter. Theoretically, we only expect this VCF to contain simulated SNPs that were already in the \panrg{}.

At the end of this workflow, we have a genotyped VCF with and without \denovo{} variant discovery for each combination of maximum nesting, \denovo{} \kmer{} size, SNP rate, and read depth (coverage).

% To avoid error-prone conversion of linear coordinates into graph coordinates the evaluation of whether the variants called by \pandora{} are correct was undertaken in a slightly more convoluted manner. We define a probe-set $P$ as a collection of probes, $p$, where $p$ represents an entry, $e$, in a VCF file, $V$. For each $e \in V$, $p$ is constructed by the concatenation of $l_w$, $e_c$, and $r_w$ (in that order), where $e_c$ is the called variant of $e$, and $l_w$ and $r_w$ are the sequences, of maximum length $w$, in the VCF reference to the left and right, respectively, of $e_c$. 

% A truth probe-set, $P_t$, was constructed from the VCF of variants added to the simulated genome and a query probe-set, $P_q$, from the variants called by \pandora{}. We then mapped all probes from $P_t$ to $P_q$ using \texttt{bwa mem}\cite{bwamem}. We then classify each mapped probe as a false positive or true positive and calculate precision and recall for the pre-\denovo{} and post-\denovo{} VCF files from \pandora{}. As expected,  \autoref{fig:simulation_roc} shows that without \denovo{} variant discovery, we are unable to find almost all introduced variants.
% In future work, we plan to add indels to the simulations.



% ==================================================================
\section{Empirical data}

In addition, we describe a framework for evaluating the validity of variant calls from \pandora{} and how to compare them with other methods which operate on single, linear reference sequence.

% \subsection{Effect of different basecalling versions}

% ==================================================================
\section{Discussion}
\label{sec:denovo-discussion}

% ==================================================================
\section{Limitations}
\label{sec:denovo-limits}
% this is refrred to by Appendix 1 - i.e., getting stick in cycles in the dbg
% ==================================================================
\section{Conclusion}

% ==================================================================
\section{Future Work}
\label{sec:denovo-fw}

% ==================================================================
\section{Availability of data and materials}