%!TEX root = ../thesis.tex
%*******************************************************************************
%*********************************** First Chapter *****************************
%*******************************************************************************

\chapter{Variant discovery in genome graphs}
\label{chap:denovo}
\ifpdf
    \graphicspath{{Chapter1/Figs/Raster/}{Chapter1/Figs/PDF/}{Chapter1/Figs/}}
\else
    \graphicspath{{Chapter1/Figs/Vector/}{Chapter1/Figs/}}
\fi
% ==================================================================
\setcounter{section}{-1}
\section{Publication and collaboration acknowledgements}
\label{sec:denovo-acknowledge}
% ==================================================================
\section{Introduction}

% ==================================================================
\section{Methods}
\label{sec:denovo-method}

We define a method that extends \pandora{}, with a subcommand \vrb{discover}, to allow for the \denovo{} discovery of variants not present a \prg{}. It is implemented within the \pandora{} code base, in the C++ programming language. 

The first step of \denovo{} variant discovery in genome graphs is finding the candidate regions of the graph that show evidence of dissimilarity from the sample's reads.

\subsection{Finding candidate regions}

The input required for finding candidate regions are a local \prg{} (node), $n$, within the \pandora{} \panrg{}; the maximum likelihood path of both sequence and \kmer{}s in $n$, $lmp_n$ and $kmp_n$ respectively; and a padding size, $w$, for the number of positions surrounding the candidate region to retrieve.

We define a candidate region, $r$, as an interval within $n$ where read depth (coverage) on $lmp_n$ is less than a given threshold, $c$, for more than $l$ and less than $m$ consecutive positions. We note that coverage is actually stored on $kmp_n$, but is stored for the whole \kmer{}. We convert the coverage on $kmp_n$ into per-position coverage on $lmp_n$ and use that for identifying low-coverage segments as just described. $m$ acts to restrict the size of variants we are able to detect. If set too large, the following steps become much slower due to the combinatorial expansion of possible paths. 

For a given read, $s$, that has a mapping to $r$, we define $s_r$ to be the subsequence of $s$ that maps to $r$, including an extra $w$ positions either side of the mapping. We define the pileup $P_r$ as the set of all $s_r \in r$.

\subsection{Enumerating paths through candidate regions}
\label{sec:path-enum}

For $r \in R$, where $R$ is the set of all candidate regions, we construct a de Bruijn graph $G_r$ from $P_r$ using the GATB library \cite{gatb2014}. 

$A_L$ and $A_R$ are defined as sets of \kmer{}s to the left and right of $r$ in the maximum likelihood path $lmp_n$. They are anchors to allow insertion of new sequences found by \denovo{} discovery into the local \prg{}. Each set has a maximum size of $k$.

We abandon \denovo{} discovery if $A_L \cap G_r = \emptyset \lor A_R \cap G_r = \emptyset$. That is, if no pairwise combination of left and right anchor \kmer{}s exists in the de Bruijn graph $G_r$.

We use sets of \kmer{}s for $A_L$ and $A_R$, rather than a single anchor \kmer{}, to provide redundancy in the case where sequencing errors cause some anchors to not be in $G_r$. We define the start anchor \kmer{}, $a_L$, as the first (left-most) $a_L \in A_L \land a_L \in G_r$. Likewise, we define the end anchor \kmer{}, $a_R$, as the left-most $a_R \in A_R \land a_R \in G_r$.

Now that we have two anchor \kmer{}s, $a_L$ and $a_R$, our goal is to find all (valid) paths between these anchors in the de Bruijn graph ($G_r$).

$T_r$ is the spanning tree obtained by performing depth-first search (DFS) on $G_r$, beginning from $a_L$. $p_r$ is defined as a path, from the root node $a_L$ of $T_r$ and ending at node $a_R$, which fulfils the following two conditions:

\begin{enumerate}
  \item $p_r$ is shorter than the maximum allowed path length.
  \item No more than $k$ nodes along $p_r$ have coverage $< (0.1 n_r e_r)$, where $e_r$ is the expected \kmer{} coverage for $r$ and $n_r$ is the number of iterations of path enumeration for $r$.
\end{enumerate}

$V_r$ is the set of all $p_r$. If $|V_r|$ is greater than a predefined threshold, $n_r$ is incremented by 1 and $V_r$ is repopulated. If $0.1n_r = 1.0$ then \denovo{} discovery is abandoned for $r$.

The second condition listed above, which relies on $n_r$ and $e_r$ has the effect of progressively increasing the amount of coverage we demand on a candidate path ($p_r$). In the first iteration, $n_r=1$, therefore we require the path has 10\% of the expected read depth (coverage). If this yields too many paths (condition 1), we restart and require all paths to have 20\% of the expected coverage. If we reach a stage where we require 100\% of the expected coverage, but still have too many paths, we quit \denovo{} discovery for the candidate region.

\subsubsection{Pruning the path-space in a candidate region}

As \pandora{} operates on both accurate and error-prone sequencing reads, the number of valid paths in $G_r$ can be very large. In testing, we found the path enumeration process can result in runtimes beyond seven days in some scenarios. The increased runtime is due to cycles that can occur in $G_r$ and exploring paths that will never reach our required end anchor ($a_R$). 

In order to reduce the path-space within $G_r$, we prune paths based on multiple criteria. Critically, this pruning happens at each step of the graph walk (path-building; \autoref{sec:path-enum}).

In addition to $T_r$, obtained by performing DFS on $G_r$, we produce a distance map $D_r$ that results from running reversed breadth-first search (BFS) on $G_r$, beginning from \emph{the end anchor} ($a_R$). We say reversed BFS as we explore the \emph{predecessors} of each node, rather than the successors. $D_r$ is implemented as a binary search tree where each node in the tree represents a \kmer{} in $G_r$ that is reachable from $a_R$ via reversed BFS. Each node additionally has an integer attached to it that describes the shortest path from that node to $a_R$.

We can use $D_r$ to prune the path-space as follows. As we walk (enumerate) the candidate path ($p_r$) in \autoref{sec:path-enum}, for each node (\kmer{}; $v$) in $G_r$, starting at $a_L$, we check if $a_R$ be reached from $v$ in a minimum of $i$ nodes, where $i$ is defined as the maximum allowed path length minus the number of nodes walked to reach $v$. If one of these conditions is not met, we abandon $p_r$. 

The advantage of this pruning process is that we never explore paths that will not reach our required end point. Additionally, we will discard any path once we have made too many loops around a graph cycle.

\noindent
In the end, for each candidate region ($r$), we are left with a collection of paths ($V_r$) between two \kmer{}s ($a_L$ and $a_R$). We create the final candidate paths by replacing the sequence between $a_L$ and $a_R$ in the maximum likelihood path ($lmp_n$) with each path ($p_r$) in $V_r$. These are written to file - with one file per candidate region. Padding the candidate paths in this way ensures they are inserted into the \prg{} in the correct location (see \autoref{sec:denovo-insert}). 

\subsection{Updating a \panrg{} with candidate paths}
\label{sec:denovo-insert}

As new paths alter the structure of a \prg{}, we cannot insert them directly, and must rebuild each \prg{} for which a candidate path is discovered.

The first step of rebuilding each local \prg{} is to add the new candidate paths to the original multiple sequence alignment (MSA). Because we padded each path with the maximum likelihood path, this ensures the novel path aligns with the correct section of the locus. We combine all candidate paths for a locus into a single, unaligned FASTA file and add them to the existing locus MSA with the \vrb{--add} routine in MAFFT \cite{katoh2012}. 

Next, \makeprg{} is run on the subsequent alignments, and the resulting updated local \prg{}s are combined into a single \panrg{} and indexed with \pandora{}. 

This updated \panrg{} can then be used as input to \pandora{} and subsequent genotyping will include the novel variants.

% ==================================================================
\section{Simulations}
\label{sec:denovo-sims}
Having described an extension of the \pandora{} program that allows for \denovo{} variant discovery, we now turn our attention to its evaluation.

\subsection{Methods}

The first step in evaluating the effect of adding \denovo{} variant calling to \pandora{} is with a simulated dataset. We aim to show that the addition of \denovo{} discovery allows \pandora{} to improve its probability of variant detection (recall) with minimal impact on the quality of the calls (precision). 

To construct our simulated dataset, we randomly select 100 gene MSAs from a pool of 29,702 obtained for \ecoli{} from the panX database \cite{panx}. Next, a local \prg{} is constructed for each MSA with \makeprg{}. We used a range of maximum nesting levels (\todo[inline]{link to intro section on make prg}) - 1, 3, 5, and 10 - in order to investigate whether \prg{} nesting has an impact on our ability to discover novel variants. The local \prg{}s are combined into a single \panrg{} for each nesting level. A random path through each \prg{} is selected using \pandora{} and concatenated together to form a single "genome" sequence. 

We subsequently add SNPs to the simulated genome at different rates of SNPs per-gene using \vrb{snp-mutator} \cite{snpmutator}. For this work, we introduce 100, 400, and 1,000 SNPs to the simulated genome, which equate to approximately 1, 4, and 10 SNPs per gene, respectively. \vrb{snp-mutator} produces a VCF of the SNPs that were introduced, along with the mutated genome sequence.

Next, we simulated 30,000 \ont{} reads from the mutated genomes using \vrb{nanosim-h} \cite{yang2017,brinda2018}. As the most recent model offered by \vrb{nanosim-h} was from the old R9 \ont{} flow cell, we trained and used a model from a freely-available \ecoli{} R9.4 dataset (\url{http://lab.loman.net/2017/03/09/ultrareads-for-nanopore/}). Each read set was randomly subsampled to a read depth (coverage) of 15, 30, 60, and 100 with \vrb{rasusa} \cite{rasusa2019} so we can investigate the impact of coverage on our ability to discover novel variants.

\pandora{}'s \vrb{discover} routine is then run, using the original panX-derived \panrg{} and the reads simulated from the mutated genome. With this approach, we know that the reads originate from a sequence in our \panrg{}, but with some SNP differences and \ont{} errors. It is possible that some of the random SNPs introduced by \vrb{snp-mutator} already exist in the \panrg{}, but this is likely to be a very small number. We use three different \kmer{} sizes for the \denovo{} discovery: 11, 13, and 15. 

After running the \vrb{discover} routine, we are left with a collection of candidate paths produced by the \denovo{} component. We then add these candidate paths back into the \panrg{} as per \autoref{sec:denovo-insert}. The updated \panrg{} is then used as input - along with the simulated reads - to \pandora{} \vrb{map} to produce a genotyped VCF that hopefully contains all of the simulated SNPs.

In parallel to this, we also run \pandora{} \vrb{map} on the original \panrg{} and simulated reads - i.e., without variant discovery. The genotyped VCF produced by this run shows how \pandora{} performed prior to the addition of \denovo{} variant discovery in this chapter. Theoretically, we only expect this VCF to contain simulated SNPs that were already in the \panrg{}.

At the end of this workflow, we have a genotyped VCF with and without \denovo{} variant discovery for each combination of maximum nesting, \denovo{} \kmer{} size, SNP rate, and read depth (coverage).

\subsection{Evaluation}

Comparing the truth VCF to the one produced by \pandora{} requires care. The variants in the truth VCF are with respect to a linear reference genome; as we only simulated SNPs, these are single positions records. However, the \pandora{} variants are with respect to a graph, and depending on the density of variation in the graph, may not appear as single position records (see \autoref{fig:min-match-len-example} for an illustration of this). 

We avoid the error-prone conversion of linear coordinates into graph coordinates, or vice versa, by using a coordinate-free evaluation. This approach maps variant \emph{probes} to each other and compares the probe sequences.  

We define a probe-set $P$ as a collection of probes, $p$, where $p$ represents an entry, $e$, in a VCF file, $V$. For each $e \in V$, $p$ is constructed by the concatenation of $l_w$, $e_c$, and $r_w$ (in that order), where $e_c$ is the called variant of $e$ (alternate allele), and $l_w$ and $r_w$ are the sequences, of maximum length $w$, in the VCF reference to the left and right, respectively, of $e_c$. For \pandora{}, the VCF reference is the maximum likelihood sequence, and for the truth VCF it is the simulated genome (without the simulated SNPs).

A truth probe-set, $P_t$, was constructed from the VCF of variants added to the simulated genome and a query probe-set, $P_q$, from the variants called by \pandora{}. We then mapped all probes from $P_t$ to $P_q$ using \texttt{bwa mem} \cite{li2013}. We classify each probe in $P_t$ as a true positive (TP) if the $e_c$ part of the probe exactly matches the sequence it aligns to in $P_q$, or a false negative (FN) otherwise. Any probe in $P_q$ that does not have a TP truth probe mapped to it is classified as a false positive (FP). We perform this assessment for the pre-\denovo{} (\vrb{no\_denovo}) and post-\denovo{} (\vrb{with\_denovo}) VCF files from \pandora{}. 

Precision is defined as the number of TPs divided by the number of TPs and FPs $precision=\frac{TP}{TP+FP}$; it represents the fraction of variant calls made that are correct. Likewise, recall is calculated as $recall=\frac{TP}{TP+FN}$ and describes the proportion of expected variants correctly discovered.

\subsection{Results}

We first look at \autoref{fig:denovo-sims}, which shows how precision and recall of the \pandora{} \denovo{} variants changes depending on the combination of parameters chosen. Those parameters were the read depth (coverage) of the simulated reads (\autoref{fig:denovo-sims-covg}), the number of SNPs introduced into the simulated genome (\autoref{fig:denovo-sims-num-snps}), the \kmer{} size used for variant discovery (\autoref{fig:denovo-sims-kmer-size}), and the maximum nesting level allowed in the \prg{}s (\autoref{fig:denovo-sims-nesting}). In total, there are 144 different combinations of parameters, and thus data points.

Perhaps the parameter that has the most obvious impact on the precision and recall is the coverage (\autoref{fig:denovo-sims-covg}). It is somewhat unsurprising that as coverage increase, so do both precision and recall. However, there does not seem to be any noticeable difference for coverage $\ge 60$.

In the best case, the highest recall and precision values are 0.91 and 1.0, respectively. In both instances, the data point is the same, with a coverage of 60, \kmer{} size of 13, number of SNPs 100, and a maximum nesting level of 10. Upon further investigation of the 9 missed variants (FNs) for this data point, six were within $2k-1$ positions of the start or end of the locus, one was a null call where the correct variant actually had the highest coverage, one was falsely called as a homopolymer deletion, and the remaining missed call never had \denovo{} discovery triggered for that region of the locus. Therefore, only 3/9 FNs for this example (the last two) were discoverable with our \denovo{} method.

The last point requires some elaboration, as it may not be clear why only three FNs in the best-performing data point were expected to be detected by \denovo{}. In the case of the null genotype call, the correct variant was discovered, and it had higher coverage than the reference allele (26 vs 11), therefore it is a failure of the genotyping. The homopolymer deletion is actually both a failure of \denovo{} and the genotyping; \denovo{} (incorrectly) discovered the candidate indel, but the genotyping confirmed it. And the variant that \denovo{} never triggered \denovo{} discovery most likely has enough coverage on the reference allele that a candidate region was not detected - by default we only flag a candidate region is coverage drops below 3.

In the case of the six missed calls near the ends of loci, these are not detectable by our current \denovo{} method as they occur within $2k-1$ positions of the boundary of a locus. The reason this makes them undetectable is related to our need for start and end anchor \kmer{}s in order to find candidate paths (\autoref{sec:path-enum}). The start and end \kmer{}s are a collection of $k$ \kmer{}s, meaning $2k-1$ positions are required surrounding a candidate region in order to be able to initiate \denovo{} discovery.

\begin{figure}
     \centering
     \begin{subfigure}[b]{0.475\textwidth}
        \includegraphics[width=1\linewidth]{Chapter1/Figs/denovo_precrec_covg.png}
        \centering
        \caption{Simulated coverage (read depth)}
        \label{fig:denovo-sims-covg}
     \end{subfigure}
     \begin{subfigure}[b]{0.475\textwidth}
         \centering
        \includegraphics[width=1\linewidth]{Chapter1/Figs/denovo_precrec_num_snps.png}
         \caption{Number of SNPs simulated}
         \label{fig:denovo-sims-num-snps}
     \end{subfigure}
     \begin{subfigure}[b]{0.475\textwidth}
        \includegraphics[width=1\linewidth]{Chapter1/Figs/denovo_precrec_kmer.png}
        \centering
        \caption{\denovo{} discovery \kmer{} size}
        \label{fig:denovo-sims-kmer-size}
     \end{subfigure}
     \begin{subfigure}[b]{0.475\textwidth}
         \centering
        \includegraphics[width=1\linewidth]{Chapter1/Figs/denovo_precrec_nesting.png}
         \caption{\prg{} maximum nesting level}
         \label{fig:denovo-sims-nesting}
     \end{subfigure}
    \caption{Recall (x-axis) and precision (y-axis) of \denovo{} variants discovered by \pandora{} on a simulated dataset. Subplots style the points by the parameter indicated in the subtitle. Each point indicates a single run of \pandora{} with a unique combination of parameters.}
        \label{fig:denovo-sims}
\end{figure}

While not an issue for the best-performing example we have just been examining, missing loci were another common source of FNs. If \pandora{} decides a locus is not present after quasi-mapping (\autoref{sec:pandora-intro}), then obviously it is impossible for \denovo{} to discover any variants in it. We note that the vast majority of missing loci have a length less than 250 base pairs (\autoref{app:denovo-missing-lengths}).

When looking across all 144 combinations of parameters, we found that, on average, 7.8\% of variants are near the ends of loci and 2.8\% are in absent loci (\autoref{fig:denovo-errors}). 

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{Chapter1/Figs/denovo_errors.png}
    \caption{The proportion of simulated SNPs that are not detectable by \denovo{} variant discovery (y-axis). The red box represents SNPs that occur in loci designated as absent by \pandora{}. The blue box depicts the SNPs that occur within $2k-1$ positions of the start or end of a locus. Each point indicates a single run of \pandora{} with a unique combination of parameters.}
    \label{fig:denovo-errors}
\end{figure}

\noindent
The parameters that we can directly control with respect to \denovo{} discovery within \pandora{} are the \prg{} maximum nesting level and the \denovo{} \kmer{} size. \autoref{fig:denovo-sims} shows no clear optimal for either of these options. However, when taking the median precision and recall values across all data points (\autoref{tab:denovo-summary}), a maximum nesting level of 5 and \denovo{} \kmer{} size of 13 seem the best choice.

\begin{table}
\centering
\begin{tabular}{@{}lll@{}}
\toprule
          & Max. nesting & \denovo{} \kmer{} size \\ \midrule
Precision & 0.934 (10)   & 0.937 (13)                                               \\
Recall    & 0.674 (5)    & 0.671 (13)                                               \\ \bottomrule
\end{tabular}
\caption{The median precision and recall for all parameter combinations, grouping by the maximum \prg{} nesting level or the \denovo{} \kmer{} size used for variant discovery in \pandora{}. The values in parentheses indicate the parameter value that leads to the specified precision or recall.}
\label{tab:denovo-summary}
\end{table}

For the final analysis of the simulation data, we look at how the precision and recall change with an increasing genotype confidence threshold. We select the data point with the optimal maximum nesting level (5) and \denovo{} \kmer{} size (13), along with the 4 SNPs per gene, as this is within the range expected for an \ecoli{} genome. In addition, we include the data points for \pandora{} with no \denovo{} discovery. Next, starting at zero and increasing by 10 until 700, we filter out any variant with a genotype confidence score below the current threshold. The purpose of this analysis is to illustrate what the cost on recall is for requiring more confident variant calls at different read depths and the impact of including \denovo{} variant discovery in \pandora{}. 

\autoref{fig:denovo-sims-roc} shows the same relationship we saw earlier: coverage has a significant impact on precision and recall. Most importantly though, it shows that the inclusion of \denovo{} discovery is vital. As shown by the lower-left inset, the best recall achievable for this set of parameters \emph{without} variant discovery is 1.0\%. This is compared to a maximum of 81.5\% when using \denovo{} discovery. Focusing on the 100x coverage data point with \denovo{} discovery, the best recall (81.5\%) leads to a precision of 97.0\%, but the cost of increasing precision to 99\% is a drop in recall to 25\%. 

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{Chapter1/Figs/denovo-sims-roc.png}
    \caption{Precision-recall curve for increasing genotype confidence score thresholds. The curves are coloured by read depth (coverage) and styled by whether or not \denovo{} variant discovery was used. Each marker/point is a different genotype confidence threshold, starting with 0 as the right-most value and increasing as the line moves towards the (top) left. The inset window in the lower-left of the figure shows the performance of \pandora{} without \denovo{} discovery. The inset on the right gives more granularity of precision for the higher-coverage data points.}
    \label{fig:denovo-sims-roc}
\end{figure}

\subsection{Summary}

In summary, we have shown that the addition of the \denovo{} variant discovery method outlined in \autoref{sec:denovo-method} gives \pandora{} the ability to find many variants not present its \panrg{}. Using simulated data, we find a \kmer{} size of 13 gives slightly better recall than 11 or 15, but that the sample read depth has the largest impact on our ability to discover novel variants.

We have also shown that on average, approximately 10.5\% of (simulated) SNPs are not detectable based on their membership in either loci \pandora{} does not detect, or within $2k-1$ positions of the end of a locus.

% ==================================================================
\section{Empirical data}

In addition, we describe a framework for evaluating the validity of variant calls from \pandora{} and how to compare them with other methods which operate on single, linear reference sequence.

% \subsection{Effect of different basecalling versions}

% ==================================================================
\section{Discussion}
\label{sec:denovo-discussion}
%  why not just assemble best sequence in dbg?
% nearly all errors in best performing params were not within the power of de novo to discover
% a better filtering strategy than gt conf alone is needed re: sims
% ==================================================================
\section{Limitations}
\label{sec:denovo-limits}
% this is refrred to by Appendix 1 - i.e., getting stick in cycles in the dbg
% homopolymer deletions - maybe ignore them? tubby?
% variants near ends of genes
% ==================================================================
\section{Conclusion}

% ==================================================================
\section{Future Work}
\label{sec:denovo-fw}
% In future work, we plan to add indels to the simulations.
% ==================================================================
\section{Availability of data and materials}